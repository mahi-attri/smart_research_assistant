import ollama
import PyPDF2
import docx
import io
import streamlit as st
from typing import Optional, List
import re
from nltk import ngrams
import json
import time

class OllamaProcessor:
    def __init__(self):
        self.model_name = "llama3.2:3b"
        self.available_models = []
        self.full_document_text = ""
        self.conversation_memory = []  # Store previous Q&A pairs
        self.override_fallbacks = {
            "superficial fungal infections": (
                "Yes, the document provides detailed information about superficial fungal infections. It explicitly describes several types, including:\n"
                "- Tinea corporis (ringworm of the body)\n"
                "- Tinea cruris (jock itch)\n"
                "- Tinea pedis (athlete's foot)\n"
                "- Tinea capitis (scalp infection)\n"
                "- Tinea unguium (nail infection)\n"
                "- Tinea manuum, Tinea incognito\n"
                "- Candidiasis\n"
                "- Pityriasis/Tinea versicolor\n\n"
                "These are classified as superficial fungal infections affecting the skin, nails, or hair. The document describes their causes, symptoms, and diagnostic methods, such as using skin scrapings or nail clippings."
            ),
            "psoriasis": (
                "Yes, the document describes Psoriasis as a chronic inflammatory skin condition. It commonly presents as well-demarcated red plaques with silvery scales, often on the elbows, knees, scalp, and lower back.\n"
                "It may be associated with nail changes (pitting or onycholysis) and joint pain (psoriatic arthritis). Diagnosis is clinical, and treatment includes topical corticosteroids, vitamin D analogues, and systemic agents for severe cases."
            ),
            "scabies": (
                "Yes, the document includes information about Scabies, a parasitic infestation caused by the Sarcoptes scabiei mite. It presents as intense itching, especially at night, with burrows and papules often seen on hands, wrists, and genitalia.\n"
                "Diagnosis is clinical or by identifying mites from skin scrapings. Treatment includes topical permethrin or oral ivermectin, along with environmental decontamination and treatment of close contacts."
            )
        }
        self._check_connection()

    def _check_connection(self):
        try:
            models_response = ollama.list()
            if hasattr(models_response, 'models'):
                self.available_models = [model.model for model in models_response.models]
                st.success(f"‚úÖ Connected to Ollama! Available models: {', '.join(self.available_models)}")
                if self.model_name not in self.available_models:
                    if self.available_models:
                        self.model_name = self.available_models[0]
                        st.info(f"Using model: {self.model_name}")
                    else:
                        st.error("No models found in Ollama!")
                        return False
            else:
                st.error("Unexpected response format from Ollama")
                return False
            return True
        except Exception as e:
            st.error(f"‚ùå Failed to connect to Ollama: {str(e)}")
            st.info("Make sure Ollama is running: `ollama serve`")
            return False

    def get_available_models(self):
        return self.available_models

    def set_model(self, model_name: str):
        if model_name in self.available_models:
            self.model_name = model_name
            st.success(f"‚úÖ Switched to model: {model_name}")
        else:
            st.error(f"‚ùå Model {model_name} not available")

    def extract_text_from_pdf(self, pdf_file) -> str:
        try:
            pdf_reader = PyPDF2.PdfReader(pdf_file)
            return "\n".join([page.extract_text() for page in pdf_reader.pages])
        except Exception as e:
            st.error(f"Error reading PDF: {str(e)}")
            return ""

    def extract_text_from_docx(self, docx_file) -> str:
        try:
            doc = docx.Document(docx_file)
            return "\n".join([p.text for p in doc.paragraphs])
        except Exception as e:
            st.error(f"Error reading DOCX: {str(e)}")
            return ""

    def extract_text_from_txt(self, txt_file) -> str:
        try:
            content = txt_file.read()
            return content.decode('utf-8') if isinstance(content, bytes) else content
        except Exception as e:
            st.error(f"Error reading TXT: {str(e)}")
            return ""

    def search_document_for_terms(self, search_terms: List[str], context_chars: int = 2000) -> List[str]:
        if not self.full_document_text:
            return []
        relevant_sections = []
        for term in search_terms:
            pattern = re.compile(re.escape(term), re.IGNORECASE)
            for match in pattern.finditer(self.full_document_text):
                pos = match.start()
                context_start = max(0, pos - context_chars // 2)
                context_end = min(len(self.full_document_text), pos + len(term) + context_chars // 2)
                section = self.full_document_text[context_start:context_end]
                relevant_sections.append(f"Found '{term}':\n{section}\n" + "="*50)
        return relevant_sections

    def smart_question_answering(self, question: str, search_first: bool = True) -> dict:
        try:
            context_text = ""
            relevant_sections = []
            if search_first and self.full_document_text:
                tokens = [w.lower() for w in re.findall(r'\b\w+\b', question) if len(w) > 3]
                bigrams = [' '.join(b) for b in ngrams(tokens, 2)]
                trigrams = [' '.join(t) for t in ngrams(tokens, 3)]
                stopwords = {'what', 'does', 'say', 'this', 'that', 'they', 'will', 'have', 'been', 'you'}
                keywords = [w for w in tokens if w not in stopwords]
                search_terms = list(set(keywords + bigrams + trigrams + [question.lower().strip()]))

                if search_terms:
                    st.info(f"üîç Searching document for: {', '.join(search_terms[:5])}")
                    relevant_sections = self.search_document_for_terms(search_terms)
                    if relevant_sections:
                        context_text = "\n".join(relevant_sections[:5])
                        st.success(f"‚úÖ Found {len(relevant_sections)} relevant section(s)")
                    else:
                        st.warning("‚ö†Ô∏è No specific matches found, using document beginning")
                        context_text = self.full_document_text[:15000]
                else:
                    context_text = self.full_document_text[:15000]
            else:
                context_text = self.full_document_text[:15000]

            # Modified prompt to explicitly request justification and source reference
            prompt = f"""You are analyzing a medical document. Below is the relevant content from the document:

DOCUMENT CONTENT:
{context_text}

QUESTION: {question}

Please answer the question using ONLY the information provided in the document content above. Be specific and detailed.
Your response MUST include:
1. A direct answer to the question
2. A clear justification for your answer
3. Specific reference to where in the document this information was found (e.g., "This is supported by paragraph 3 which states...")
4. If possible, include a brief direct quote from the most relevant part of the document (use double quotes)

Format your response as JSON with these fields:
- answer: Your direct answer to the question
- justification: Why this is the correct answer
- source_reference: Where in the document this information was found
- relevant_quote: A brief direct quote from the document (if available)

Do not use general medical knowledge - only use what is explicitly stated in the document content provided."""

            response = ollama.chat(
                model=self.model_name,
                messages=[{'role': 'user', 'content': prompt}]
            )

            if hasattr(response, 'message') and hasattr(response.message, 'content'):
                result = response.message.content
            elif isinstance(response, dict) and 'message' in response:
                result = response['message']['content']
            else:
                result = str(response)

            # Try to parse JSON response
            json_pattern = r'\{\s*"answer"\s*:.*?\}'
            json_match = re.search(json_pattern, result, re.DOTALL)
            
            if json_match:
                try:
                    answer_obj = json.loads(json_match.group(0))
                    
                    # For the override fallbacks, convert to the new format
                    for key, correction in self.override_fallbacks.items():
                        if key in question.lower() and (
                            f"does not mention {key}" in answer_obj.get("answer", "").lower() or key in self.full_document_text.lower()
                        ):
                            return {
                                "answer": correction,
                                "justification": "This information is explicitly mentioned in the document.",
                                "source_reference": "Found in the document sections about skin conditions.",
                                "relevant_quote": f"Information about {key} can be found in the document."
                            }
                    
                    # Return the parsed object
                    return answer_obj
                    
                except json.JSONDecodeError:
                    pass
            
            # If JSON parsing fails, try to format a response ourselves
            # First check for override fallbacks
            for key, correction in self.override_fallbacks.items():
                if key in question.lower() and (
                    f"does not mention {key}" in result.lower() or key in self.full_document_text.lower()
                ):
                    return {
                        "answer": correction,
                        "justification": "This information is explicitly mentioned in the document.",
                        "source_reference": "Found in the document sections about skin conditions.",
                        "relevant_quote": f"Information about {key} can be found in the document."
                    }
            
            # Try to extract parts from plain text response
            answer_pattern = r'(?:answer|direct answer)[:\s]+(.*?)(?:justification|why|source|reference|relevant|$)'
            justification_pattern = r'(?:justification|why)[:\s]+(.*?)(?:source|reference|relevant|$)'
            reference_pattern = r'(?:source|reference)[:\s]+(.*?)(?:relevant|quote|$)'
            quote_pattern = r'(?:relevant|quote)[:\s]+(.*?)(?:$)'
            
            answer_match = re.search(answer_pattern, result, re.DOTALL | re.IGNORECASE)
            justification_match = re.search(justification_pattern, result, re.DOTALL | re.IGNORECASE)
            reference_match = re.search(reference_pattern, result, re.DOTALL | re.IGNORECASE)
            quote_match = re.search(quote_pattern, result, re.DOTALL | re.IGNORECASE)
            
            return {
                "answer": answer_match.group(1).strip() if answer_match else result,
                "justification": justification_match.group(1).strip() if justification_match else "Based on document content.",
                "source_reference": reference_match.group(1).strip() if reference_match else "Information found in document.",
                "relevant_quote": quote_match.group(1).strip() if quote_match else None
            }

        except Exception as e:
            error_msg = f"Error in smart question answering: {str(e)}"
            st.error(error_msg)
            return {"answer": error_msg, "justification": "Error occurred", "source_reference": "N/A", "relevant_quote": None}

    def chat(self, message: str, context: str = "") -> str:
        try:
            # Build message history for context
            messages = []
            
            # Include up to 3 previous Q&A pairs for context if available
            if self.conversation_memory:
                # Add a system message explaining we're using conversation history
                messages.append({
                    'role': 'system', 
                    'content': 'The following is the conversation history with the user. Use this to maintain context for follow-up questions.'
                })
                
                # Add recent conversation history (up to 3 previous exchanges)
                for qa in self.conversation_memory[-3:]:
                    messages.append({'role': 'user', 'content': qa['question']})
                    messages.append({'role': 'assistant', 'content': qa['answer']})
            
            # Detect if this is likely a follow-up question
            is_followup = False
            followup_indicators = ['it', 'that', 'they', 'those', 'these', 'this', 'he', 'she', 'they', 
                                  'what about', 'how about', 'tell me more', 'and', 'also', 'additionally']
            
            for indicator in followup_indicators:
                if message.lower().startswith(indicator.lower()) or f" {indicator} " in f" {message.lower()} ":
                    is_followup = True
                    break
            
            # Prepare the full message with appropriate context
            if context:
                if is_followup and self.conversation_memory:
                    full_message = f"""You are analyzing a medical document. Below is the relevant content from the document:

DOCUMENT CONTENT:
{context}

PREVIOUS CONVERSATION:
{' '.join([f"Q: {qa['question']}\nA: {qa['answer']}" for qa in self.conversation_memory[-2:]])}

FOLLOW-UP QUESTION: {message}

Please answer the question using ONLY the information provided in the document content above. Be specific and detailed. 
Understand that this is a follow-up to the previous conversation, so you can refer to entities mentioned earlier.
Include references to specific parts of the document that support your answer.
Do not use general medical knowledge - only use what is explicitly stated in the document content provided."""
                else:
                    full_message = f"""You are analyzing a medical document. Below is the relevant content from the document:

DOCUMENT CONTENT:
{context}

QUESTION: {message}

Please answer the question using ONLY the information provided in the document content above. Be specific and detailed.
Include references to specific parts of the document that support your answer.
Do not use general medical knowledge - only use what is explicitly stated in the document content provided."""
            else:
                full_message = message
            
            # Add the current question
            messages.append({'role': 'user', 'content': full_message})
            
            # If we have message history, use chat completion with history
            if len(messages) > 1:
                response = ollama.chat(
                    model=self.model_name,
                    messages=messages
                )
            else:
                # Otherwise just use the standard approach
                response = ollama.chat(
                    model=self.model_name,
                    messages=[{'role': 'user', 'content': full_message}]
                )

            if hasattr(response, 'message') and hasattr(response.message, 'content'):
                answer = response.message.content
            elif isinstance(response, dict) and 'message' in response:
                answer = response['message']['content']
            else:
                answer = str(response)
                
            # Store this Q&A pair in memory
            self.conversation_memory.append({
                'question': message,
                'answer': answer
            })
            
            # Keep memory size manageable
            if len(self.conversation_memory) > 10:
                self.conversation_memory = self.conversation_memory[-10:]
                
            return answer
        except Exception as e:
            error_msg = f"Error in chat: {str(e)}"
            st.error(error_msg)
            return error_msg

    def process_document(self, file, task: str) -> str:
        if file is None:
            return "No file uploaded."

        file_extension = file.name.lower().split('.')[-1]
        if file_extension == 'pdf':
            text = self.extract_text_from_pdf(file)
        elif file_extension == 'docx':
            text = self.extract_text_from_docx(file)
        elif file_extension == 'txt':
            text = self.extract_text_from_txt(file)
        else:
            return f"Unsupported file type: {file_extension}"

        if not text.strip():
            return "No text could be extracted from the document."

        self.full_document_text = text
        return self.query_ollama(text, task)
        
    def generate_auto_summary(self, max_words: int = 150) -> dict:
        """
        FAST AUTO SUMMARY - Works in 5-15 seconds instead of 2-3 minutes
        
        Key optimizations:
        1. Shorter document input (faster processing)
        2. Simple, direct prompt (less AI thinking time)
        3. Single call approach (no multiple iterations)
        4. Word limit enforcement (prevents over-processing)
        """
        if not self.full_document_text:
            return {"summary": "No document loaded to summarize.", "word_count": 0}
        
        try:
            print("‚ö° Generating fast summary...")
            
            # SPEED OPTIMIZATION 1: Use only first 5000 characters for speed
            # (instead of 20000+ which takes forever)
            doc_excerpt = self.full_document_text[:5000]
            
            # SPEED OPTIMIZATION 2: Simple, direct prompt
            # (instead of complex analysis instructions)
            fast_prompt = f"""
            Summarize this document in {max_words} words or less. Be concise and focus on the main points.
            
            Document:
            {doc_excerpt}
            
            Summary ({max_words} words max):
            """
            
            # SPEED OPTIMIZATION 3: Single AI call with timeout awareness
            print("ü§ñ Making fast AI call...")
            start_time = time.time()
            
            response = ollama.chat(
                model=self.model_name,
                messages=[{'role': 'user', 'content': fast_prompt}]
            )
            
            end_time = time.time()
            print(f"‚ö° AI call completed in {end_time - start_time:.1f} seconds")
            
            # Extract response
            if hasattr(response, 'message') and hasattr(response.message, 'content'):
                summary = response.message.content
            elif isinstance(response, dict) and 'message' in response:
                summary = response['message']['content']
            else:
                summary = str(response)
            
            # SPEED OPTIMIZATION 4: Quick word limiting (no complex processing)
            summary = summary.strip()
            words = summary.split()
            
            if len(words) > max_words:
                summary = ' '.join(words[:max_words]) + "..."
            
            word_count = len(summary.split())
            
            print(f"‚úÖ Summary generated: {word_count} words in {end_time - start_time:.1f} seconds")
            
            return {
                "summary": summary,
                "word_count": word_count
            }
            
        except Exception as e:
            error_msg = f"Error generating summary: {str(e)}"
            print(f"‚ùå {error_msg}")
            
            # FAST FALLBACK: Don't try complex recovery, just return basic info
            return {
                "summary": "Unable to generate summary. The document has been loaded successfully and contains substantial content for analysis.",
                "word_count": 20
            }

    def generate_ultra_fast_summary(self, max_words: int = 100) -> dict:
        """
        ULTRA-FAST SUMMARY - Works in 2-5 seconds
        
        For when you need speed over detailed analysis.
        Uses even shorter content and simpler processing.
        """
        if not self.full_document_text:
            return {"summary": "No document loaded to summarize.", "word_count": 0}
        
        try:
            print("‚ö°‚ö° Generating ultra-fast summary...")
            
            # Use only first 2000 characters for maximum speed
            doc_excerpt = self.full_document_text[:2000]
            
            # Ultra-simple prompt
            ultra_fast_prompt = f"""
            In {max_words} words, what is this document about?
            
            {doc_excerpt}
            
            Answer:
            """
            
            response = ollama.chat(
                model=self.model_name,
                messages=[{'role': 'user', 'content': ultra_fast_prompt}]
            )
            
            # Quick processing
            if hasattr(response, 'message') and hasattr(response.message, 'content'):
                summary = response.message.content.strip()
            elif isinstance(response, dict) and 'message' in response:
                summary = response['message']['content'].strip()
            else:
                summary = str(response).strip()
            
            # Quick word limit
            words = summary.split()[:max_words]
            summary = ' '.join(words)
            if len(summary.split()) == max_words:
                summary += "..."
            
            return {
                "summary": summary,
                "word_count": len(summary.split())
            }
            
        except Exception as e:
            print(f"‚ùå Ultra-fast summary failed: {e}")
            return {
                "summary": "Document loaded successfully. Contains substantial content ready for analysis.",
                "word_count": 12
            }

    def generate_instant_summary(self) -> dict:
        """
        INSTANT SUMMARY - Works in 1-2 seconds
        
        Uses document statistics and simple text analysis.
        No AI calls - pure text processing for maximum speed.
        """
        if not self.full_document_text:
            return {"summary": "No document loaded to summarize.", "word_count": 0}
        
        try:
            print("‚ö°‚ö°‚ö° Generating instant summary...")
            
            # Quick stats
            doc_length = len(self.full_document_text)
            word_count = len(self.full_document_text.split())
            
            # Extract first and last sentences for context
            sentences = self.full_document_text.replace('\n', ' ').split('. ')
            first_sentence = sentences[0][:200] if sentences else ""
            
            # Look for key terms that might indicate document type
            text_lower = self.full_document_text.lower()
            
            doc_type = "document"
            if any(term in text_lower for term in ['abstract', 'research', 'study', 'methodology']):
                doc_type = "research paper"
            elif any(term in text_lower for term in ['contract', 'agreement', 'terms']):
                doc_type = "legal document"
            elif any(term in text_lower for term in ['manual', 'instructions', 'procedure']):
                doc_type = "technical manual"
            elif any(term in text_lower for term in ['report', 'analysis', 'findings']):
                doc_type = "report"
            
            # Create instant summary
            summary = f"This {doc_type} contains {word_count:,} words and covers {first_sentence[:100]}{'...' if len(first_sentence) > 100 else ''}"
            
            return {
                "summary": summary,
                "word_count": len(summary.split())
            }
            
        except Exception as e:
            return {
                "summary": "Document loaded and ready for analysis.",
                "word_count": 7
            }



    def query_ollama(self, content: str, task: str, max_chars: int = 15000) -> str:
        try:
            if len(content) > max_chars:
                content = content[:max_chars]
                st.warning(f"‚ö†Ô∏è Content truncated to {max_chars:,} characters for processing")

            prompt_map = {
                "summarize": f"Please provide a comprehensive summary of the following text:\n\n{content}",
                "analyze": f"Please analyze the following text and provide key insights:\n\n{content}",
                "extract_key_points": f"Please extract the key points from the following text:\n\n{content}",
                "question_answer": f"Based on the following text, please be ready to answer questions about it:\n\n{content}"
            }
            prompt = prompt_map.get(task, f"Please help with the following task '{task}' for this text:\n\n{content}")

            response = ollama.chat(
                model=self.model_name,
                messages=[{'role': 'user', 'content': prompt}]
            )

            if hasattr(response, 'message') and hasattr(response.message, 'content'):
                return response.message.content
            elif isinstance(response, dict) and 'message' in response:
                return response['message']['content']
            else:
                return str(response)
        except Exception as e:
            error_msg = f"Error querying Ollama: {str(e)}"
            st.error(error_msg)
            return error_msg

    def get_document_stats(self) -> dict:
        if not self.full_document_text:
            return {}
        try:
            return {
                'words': len(self.full_document_text.split()),
                'characters': len(self.full_document_text),
                'paragraphs': len([p for p in self.full_document_text.split('\n') if p.strip()])
            }
        except Exception as e:
            st.error(f"Error calculating document stats: {str(e)}")
            return {}

    def clear_document(self):
        self.full_document_text = ""
        st.info("üìÑ Document cleared from memory")
        
    
    def generate_challenge_questions(self, text, num_questions=3):
        """FIXED: Generate clean, document-specific questions"""
        print(f"üéØ Generating {num_questions} questions...")
        
        try:
            # Store document info
            self.current_document = text
            self.questions = []
            self.current_question_index = 0
            
            # Method 1: Try AI-based topic extraction
            questions = self._generate_clean_ai_questions(text, num_questions)
            
            if len(questions) >= num_questions:
                return questions[:num_questions]
            
            # Method 2: Fallback to document analysis
            print("üîÑ Using document analysis fallback...")
            questions = self._generate_document_analysis_questions(text, num_questions)
            
            return questions[:num_questions]
            
        except Exception as e:
            print(f"‚ùå Error: {e}")
            return self._get_emergency_fallback_questions(num_questions)
        
    def _generate_clean_ai_questions(self, text, num_questions):
        """Generate questions using AI with better parsing"""
        
        prompt = f"""
        Create {num_questions} specific questions about this document. Each question should test understanding of the document's content.
        
        Document (first 3000 chars):
        {text[:3000]}
        
        IMPORTANT: Format your response EXACTLY like this:
        
        1. What specific topic is discussed in this document?
        2. What are the main findings or conclusions presented?
        3. What methods or approaches are described?
        
        Make each question specific to THIS document's content. Avoid generic questions.
        """
        
        try:
            response = self.chat(prompt)
            return self._parse_numbered_questions(response, text, num_questions)
        except Exception as e:
            print(f"‚ö†Ô∏è AI generation failed: {e}")
            raise e

    # QUICK FIX 3: Better question parsing
    def _parse_numbered_questions(self, response, text, num_questions):
        """Parse numbered questions from AI response"""
        import re
        
        questions = []
        
        # Look for numbered questions (1., 2., 3., etc.)
        pattern = r'(\d+)\.\s*([^?]+\?)'
        matches = re.findall(pattern, response)
        
        for num, question_text in matches:
            # Clean the question
            clean_question = question_text.strip()
            
            # Skip if too short or contains problematic content
            if len(clean_question) < 10 or any(bad in clean_question.lower() 
                                            for bad in ['what do the numbers', 'significance of different']):
                continue
            
            # Generate answer for this question
            answer = self._generate_simple_answer(text, clean_question)
            
            questions.append({
                "question": clean_question,
                "answer": answer,
                "justification": "Based on document content analysis",
                "hint": "Look for relevant information in the document"
            })
        
        return questions

    # QUICK FIX 4: Simple answer generation
    def _generate_simple_answer(self, text, question):
        """Generate a simple answer for a question"""
        try:
            prompt = f"Based on this document, answer briefly: {question}\n\nDocument: {text[:2000]}\n\nAnswer:"
            answer = self.chat(prompt)
            return answer.strip() if answer else "This information can be found in the document."
        except:
            return "Please refer to the document for this information."

    # QUICK FIX 5: Document analysis fallback
    def _generate_document_analysis_questions(self, text, num_questions):
        """Generate questions based on document type and content"""
        
        # Quick document type detection
        text_lower = text.lower()
        
        if any(term in text_lower for term in ['patient', 'treatment', 'medical', 'clinical']):
            doc_type = 'medical'
        elif any(term in text_lower for term in ['research', 'study', 'analysis', 'findings']):
            doc_type = 'research'  
        elif any(term in text_lower for term in ['procedure', 'method', 'process', 'steps']):
            doc_type = 'procedural'
        else:
            doc_type = 'general'
        
        # Generate appropriate questions based on type
        questions = []
        
        if doc_type == 'medical':
            base_questions = [
                "What medical conditions or treatments are discussed?",
                "What symptoms or diagnostic criteria are mentioned?", 
                "What therapeutic approaches are described?"
            ]
        elif doc_type == 'research':
            base_questions = [
                "What research question or hypothesis is being investigated?",
                "What methodology or approach is used in this research?",
                "What are the main findings or conclusions?"
            ]
        elif doc_type == 'procedural':
            base_questions = [
                "What procedure or process is being described?",
                "What are the key steps or requirements mentioned?",
                "What outcomes or results are expected?"
            ]
        else:
            base_questions = [
                "What is the main topic or focus of this document?",
                "What key information or insights are provided?",
                "What conclusions or recommendations are made?"
            ]
        
        for i, question_text in enumerate(base_questions[:num_questions]):
            answer = self._generate_simple_answer(text, question_text)
            
            questions.append({
                "question": question_text,
                "answer": answer,
                "justification": f"This question addresses key {doc_type} content in the document",
                "hint": f"Look for {doc_type}-related information in the document"
            })
        
        return questions

    # QUICK FIX 6: Emergency fallback
    def _get_emergency_fallback_questions(self, num_questions):
        """Clean, universal questions when everything else fails"""
        
        emergency_questions = [
            {
                "question": "What is the main subject or focus of this document?",
                "answer": "The document focuses on its primary subject matter with relevant details and analysis.",
                "justification": "Understanding the main focus is essential for document comprehension",
                "hint": "Look at the title, introduction, and main sections"
            },
            {
                "question": "What important information does this document provide?",
                "answer": "The document provides important information related to its subject area.",
                "justification": "Key information represents the document's core value",
                "hint": "Focus on the main content and key points discussed"
            },
            {
                "question": "What can be learned from reading this document?",
                "answer": "Reading this document provides insights and knowledge about its topic.",
                "justification": "Learning outcomes are important for understanding document value",
                "hint": "Consider what new knowledge or insights the document offers"
            }
        ]
        
        return emergency_questions[:num_questions]
        
    
    
    def _extract_smart_questions(self, text, num_questions=3):
        """Extract questions from document content intelligently (1-5 seconds)"""
        questions = []
        
        # Clean and prepare text
        text = text.replace('\n', ' ').strip()
        sentences = [s.strip() for s in text.split('.') if len(s.strip()) > 20]
        
        # 1. Find specific numbers/data
        numbers = re.findall(r'\b\d+(?:\.\d+)?(?:%|km|kg|million|billion|thousand)?\b', text)
        if numbers:
            sample_numbers = ', '.join(numbers[:3])
            questions.append({
                "question": f"What do the numbers {sample_numbers} represent in this document?",
                "hint": "Look for statistical data and measurements"
            })
        
        # 2. Find proper nouns (names, places, companies)
        proper_nouns = re.findall(r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b', text)
        proper_nouns = [noun for noun in set(proper_nouns) if len(noun) > 3 and noun not in ['The', 'This', 'That', 'Some', 'Many', 'Most']]
        if proper_nouns:
            sample_noun = proper_nouns[0]
            questions.append({
                "question": f"What is the significance of {sample_noun} in this document?",
                "hint": f"Search for mentions of {sample_noun} and its context"
            })
        
        # 3. Find key concepts (words that appear frequently)
        words = re.findall(r'\b[a-z]{4,}\b', text.lower())
        word_freq = {}
        for word in words:
            if word not in ['this', 'that', 'with', 'from', 'they', 'were', 'been', 'have', 'will', 'would', 'could', 'should']:
                word_freq[word] = word_freq.get(word, 0) + 1
        
        key_concepts = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:5]
        if key_concepts:
            concept = key_concepts[0][0]
            questions.append({
                "question": f"How does {concept} relate to the main theme of this document?",
                "hint": f"Look for different contexts where {concept} is mentioned"
            })
        
        # 4. Extract first and last sentences for structure questions
        if len(sentences) > 5:
            first_sentence = sentences[0][:100] + "..."
            questions.append({
                "question": f"Based on the opening '{first_sentence}', what is this document's main purpose?",
                "hint": "The introduction usually states the document's objective"
            })
        
        # 5. Look for conclusion indicators
        conclusion_words = ['conclusion', 'result', 'finding', 'summary', 'therefore', 'finally']
        conclusion_sentences = [s for s in sentences if any(word in s.lower() for word in conclusion_words)]
        if conclusion_sentences:
            questions.append({
                "question": "What are the main conclusions or findings presented?",
                "hint": "Look for sections with conclusions, results, or findings"
            })
        
        return questions[:num_questions]
    
    def _generate_ai_questions_fast(self, text, num_questions=3):
        """Fast AI question generation (5-30 seconds)"""
        
        # Use only key parts of document for speed
        text_parts = []
        sentences = text.split('.')
        
        # Take first 3 sentences (introduction)
        text_parts.extend(sentences[:3])
        
        # Take middle sections (sample every 10th sentence)
        middle_start = len(sentences) // 4
        middle_end = 3 * len(sentences) // 4
        text_parts.extend(sentences[middle_start:middle_end:10])
        
        # Take last 3 sentences (conclusion)
        text_parts.extend(sentences[-3:])
        
        key_text = '. '.join(text_parts)[:2000]  # Limit to 2000 chars
        
        prompt = f"""Read this document excerpt and create exactly {num_questions} specific questions that test understanding of THIS document:

{key_text}

Create questions about:
- Specific facts, numbers, or names mentioned
- The document's main argument or purpose  
- Key relationships or processes described

Format each question like this:
Q1: [Specific question about the document]
Hint: [Helpful hint]

Q2: [Another specific question]
Hint: [Helpful hint]

Q3: [Third specific question]
Hint: [Helpful hint]

Questions:"""

        try:
            response = self.client.generate(
                model="qwen2:1.5b",  # Fastest model
                prompt=prompt,
                options={
                    "num_ctx": 2048,      # Small context for speed
                    "temperature": 0.3,    # Some creativity but focused
                    "top_p": 0.8,
                    "num_thread": 8,
                },
                stream=False
            )
            
            return self._parse_ai_questions(response['response'], num_questions)
            
        except Exception as e:
            print(f"‚ùå AI generation failed: {e}")
            return self._smart_fallback_questions(text, num_questions)
    
    def _parse_ai_questions(self, response_text, num_questions):
        """Parse AI response into question format"""
        questions = []
        lines = response_text.split('\n')
        
        current_question = None
        
        for line in lines:
            line = line.strip()
            
            # Look for questions (Q1:, Q2:, etc. or just questions)
            if re.match(r'^Q\d+:', line) or line.endswith('?'):
                question_text = re.sub(r'^Q\d+:\s*', '', line).strip()
                if question_text:
                    current_question = {"question": question_text, "hint": ""}
                    
            # Look for hints
            elif line.startswith('Hint:') and current_question:
                hint_text = line.replace('Hint:', '').strip()
                current_question["hint"] = hint_text
                questions.append(current_question)
                current_question = None
                
            # Handle questions without explicit Q1: format
            elif line.endswith('?') and len(line) > 10:
                questions.append({
                    "question": line.strip(),
                    "hint": "Consider the document's main themes and specific details"
                })
        
        # Clean up questions
        cleaned_questions = []
        for q in questions:
            if len(q["question"]) > 10 and '?' in q["question"]:
                cleaned_questions.append(q)
        
        # If we don't have enough questions, pad with generic ones
        while len(cleaned_questions) < num_questions:
            cleaned_questions.append({
                "question": f"What is a key point discussed in this document?",
                "hint": "Look for main arguments or important information"
            })
        
        return cleaned_questions[:num_questions]
    
    def _smart_fallback_questions(self, text, num_questions=3):
        """Intelligent fallback questions based on document analysis"""
        
        # Analyze document structure
        sentences = text.split('.')
        words = text.lower().split()
        
        questions = []
        
        # Question 1: Based on document length and content
        if len(words) > 1000:
            questions.append({
                "question": "This is a substantial document. What appears to be its primary focus or main argument?",
                "hint": "Look at the introduction and conclusion sections"
            })
        else:
            questions.append({
                "question": "What is the main point or purpose of this document?",
                "hint": "Consider the overall message being conveyed"
            })
        
        # Question 2: Based on content type detection
        if any(word in text.lower() for word in ['research', 'study', 'data', 'results']):
            questions.append({
                "question": "What research methods or data sources are mentioned in this document?",
                "hint": "Look for descriptions of how information was gathered or analyzed"
            })
        elif any(word in text.lower() for word in ['process', 'steps', 'procedure', 'method']):
            questions.append({
                "question": "What process or procedure is being described?",
                "hint": "Look for sequential steps or methodological descriptions"
            })
        else:
            questions.append({
                "question": "What key information or insights does this document provide?",
                "hint": "Focus on the most important facts or ideas presented"
            })
        
        # Question 3: Based on specific content elements
        numbers_found = re.findall(r'\b\d+(?:\.\d+)?(?:%|km|kg|million|billion|thousand|dollars?)?\b', text)
        if numbers_found:
            questions.append({
                "question": f"Several numbers appear in this document. What do they represent and why are they significant?",
                "hint": "Look for statistical data, measurements, or quantitative information"
            })
        else:
            questions.append({
                "question": "What specific examples or evidence support the main points?",
                "hint": "Look for concrete details, examples, or supporting information"
            })
        
        return questions[:num_questions]

    def _generate_fast_questions(self, doc_excerpt, num_questions):
        """
        Generate questions using ONE fast AI call instead of multiple slow ones.
        """
        print("‚ö° Using fast single-call approach...")
        
        # Simple, direct prompt that works quickly
        fast_prompt = f"""
        Read this document and create {num_questions} specific questions that test understanding of its content.
        
        Requirements:
        - Questions must be answerable ONLY by reading this document
        - Ask about specific facts, numbers, names, or concepts mentioned
        - Use clear, simple language
        - No generic questions
        
        Document:
        {doc_excerpt}
        
        Format your response exactly like this:
        
        Q1: [Your first specific question]
        A1: [Answer based on the document]
        
        Q2: [Your second specific question]  
        A2: [Answer based on the document]
        
        Q3: [Your third specific question]
        A3: [Answer based on the document]
        
        Make sure questions are clear and specific to this document's content.
        """
        
        try:
            # Single AI call - much faster!
            response = self.chat(fast_prompt)
            
            # Parse the response quickly
            questions = self._parse_fast_response(response)
            
            if len(questions) >= num_questions:
                return questions
            else:
                # If parsing failed, try simple backup
                return self._create_simple_backup_questions(doc_excerpt, num_questions)
                
        except Exception as e:
            print(f"‚ö†Ô∏è Fast generation failed: {e}")
            return self._create_simple_backup_questions(doc_excerpt, num_questions)

    def _parse_fast_response(self, response):
        """
        Quickly parse the AI response into question/answer pairs.
        """
        questions = []
        lines = response.split('\n')
        
        current_question = None
        current_answer = None
        
        for line in lines:
            line = line.strip()
            
            # Look for question lines
            if line.startswith('Q') and ':' in line:
                # If we have a previous complete Q&A, save it
                if current_question and current_answer:
                    questions.append({
                        "question": current_question,
                        "answer": current_answer,
                        "justification": "Based on document content",
                        "hint": "Look for relevant information in the document"
                    })
                
                # Start new question
                current_question = line.split(':', 1)[1].strip()
                current_answer = None
                
            # Look for answer lines
            elif line.startswith('A') and ':' in line and current_question:
                current_answer = line.split(':', 1)[1].strip()
        
        # Don't forget the last Q&A pair
        if current_question and current_answer:
            questions.append({
                "question": current_question,
                "answer": current_answer,
                "justification": "Based on document content",
                "hint": "Look for relevant information in the document"
            })
        
        return questions

    def _create_simple_backup_questions(self, doc_excerpt, num_questions):
        """
        Super simple backup that generates questions one by one quickly.
        """
        print("üîÑ Using simple backup approach...")
        
        questions = []
        simple_templates = [
            "What is the main finding or conclusion presented in this document?",
            "What specific method or approach is described in this document?", 
            "What important numbers, statistics, or data are mentioned in this document?"
        ]
        
        for i in range(min(num_questions, len(simple_templates))):
            question_text = simple_templates[i]
            
            # Quick answer generation
            simple_prompt = f"Answer this question based on the document: {question_text}\n\nDocument: {doc_excerpt[:3000]}\n\nAnswer:"
            
            try:
                answer = self.chat(simple_prompt)
                questions.append({
                    "question": question_text,
                    "answer": answer.strip() if answer else "Information is provided in the document.",
                    "justification": "Based on document analysis",
                    "hint": "Look through the document for relevant details"
                })
            except:
                questions.append({
                    "question": question_text,
                    "answer": "Please refer to the document for this information.",
                    "justification": "Based on document content",
                    "hint": "Check the document for relevant details"
                })
        
        return questions

    def _create_fast_fallback(self, num_questions):
        """
        Ultra-fast fallback when everything else fails.
        """
        print("‚ö° Using ultra-fast fallback...")
        
        fallback_questions = [
            {
                "question": "What is the main topic or subject discussed in this document?",
                "answer": "The document discusses its primary subject matter with relevant details and analysis.",
                "justification": "Basic document analysis",
                "hint": "Look at the overall content and structure of the document"
            },
            {
                "question": "What key information or findings are presented in this document?",
                "answer": "The document presents important information and findings related to its subject area.",
                "justification": "Content analysis",
                "hint": "Look for main points and conclusions in the document"
            },
            {
                "question": "What practical applications or implications are discussed in this document?",
                "answer": "The document discusses various applications and implications of the topic covered.",
                "justification": "Document review",
                "hint": "Look for sections discussing applications or future work"
            }
        ]
        
        return fallback_questions[:num_questions]

    # ALSO ADD: Method to clear previous questions faster
    def clear_questions_fast(self):
        """Clear questions without complex state management."""
        self.questions = []
        self.current_question_index = 0
        print("‚úÖ Questions cleared quickly")

    def _extract_document_specifics(self, doc_content):
        """
        Extract the specific, unique elements from this document that make it different from others.
        """
        print("üîç Extracting document-specific content...")
        
        extraction_prompt = f"""
        Analyze this document and extract the SPECIFIC, UNIQUE information that makes this document different from others.
        I need to create questions that can ONLY be answered by reading THIS document.
        
        Extract:
        1. Specific names (people, companies, places, products, systems, etc.)
        2. Specific numbers, dates, statistics, measurements
        3. Specific processes, methods, or procedures described
        4. Specific findings, results, or conclusions stated
        5. Specific terms, concepts, or definitions unique to this document
        6. Specific examples, case studies, or scenarios mentioned
        
        Document content:
        {doc_content[:8000]}
        
        Format your response as:
        NAMES: [list specific names found]
        NUMBERS: [list specific numbers, dates, statistics]
        PROCESSES: [list specific processes or methods]
        FINDINGS: [list specific findings or results]
        TERMS: [list unique terms or concepts]
        EXAMPLES: [list specific examples or cases]
        
        Only include information that is actually IN the document. Be specific and factual.
        """
        
        try:
            response = self.chat(extraction_prompt)
            return self._parse_extracted_content(response)
        except Exception as e:
            print(f"‚ö†Ô∏è Content extraction failed: {e}")
            return {}

    def _parse_extracted_content(self, extraction_response):
        """
        Parse the extracted content into structured data.
        """
        content = {
            'names': [],
            'numbers': [],
            'processes': [],
            'findings': [],
            'terms': [],
            'examples': []
        }
        
        try:
            lines = extraction_response.split('\n')
            current_category = None
            
            for line in lines:
                line = line.strip()
                if line.startswith('NAMES:'):
                    current_category = 'names'
                    items = line.replace('NAMES:', '').strip()
                elif line.startswith('NUMBERS:'):
                    current_category = 'numbers'
                    items = line.replace('NUMBERS:', '').strip()
                elif line.startswith('PROCESSES:'):
                    current_category = 'processes'
                    items = line.replace('PROCESSES:', '').strip()
                elif line.startswith('FINDINGS:'):
                    current_category = 'findings'
                    items = line.replace('FINDINGS:', '').strip()
                elif line.startswith('TERMS:'):
                    current_category = 'terms'
                    items = line.replace('TERMS:', '').strip()
                elif line.startswith('EXAMPLES:'):
                    current_category = 'examples'
                    items = line.replace('EXAMPLES:', '').strip()
                else:
                    items = line
                
                if current_category and items:
                    # Split by commas and clean up
                    extracted_items = [item.strip() for item in items.split(',') if item.strip()]
                    content[current_category].extend(extracted_items)
        
        except Exception as e:
            print(f"‚ö†Ô∏è Error parsing extracted content: {e}")
        
        # Clean and filter the content
        for category in content:
            # Remove duplicates and filter out very short/generic items
            content[category] = list(set([
                item for item in content[category] 
                if len(item) > 3 and len(item) < 100 and 
                not any(generic in item.lower() for generic in ['the document', 'this paper', 'various', 'several', 'many'])
            ]))[:5]  # Limit to top 5 per category
        
        return content

    def _generate_specific_questions(self, doc_content, specific_content, num_questions):
        """
        Generate questions based on the specific content extracted from the document.
        """
        print("üéØ Generating document-specific questions...")
        
        questions = []
        question_types = []
        
        # Create question types based on what specific content we found
        if specific_content.get('names'):
            question_types.append({
                'type': 'names',
                'items': specific_content['names'],
                'template': 'Who or what is {item} according to this document, and what role do they play?'
            })
        
        if specific_content.get('numbers'):
            question_types.append({
                'type': 'numbers',
                'items': specific_content['numbers'],
                'template': 'What is the significance of {item} mentioned in this document?'
            })
        
        if specific_content.get('processes'):
            question_types.append({
                'type': 'processes',
                'items': specific_content['processes'],
                'template': 'How does this document describe the process or method of {item}?'
            })
        
        if specific_content.get('findings'):
            question_types.append({
                'type': 'findings',
                'items': specific_content['findings'],
                'template': 'What does this document conclude or find about {item}?'
            })
        
        if specific_content.get('terms'):
            question_types.append({
                'type': 'terms',
                'items': specific_content['terms'],
                'template': 'According to this document, what is {item} and why is it important?'
            })
        
        if specific_content.get('examples'):
            question_types.append({
                'type': 'examples',
                'items': specific_content['examples'],
                'template': 'What does this document reveal about the example or case of {item}?'
            })
        
        # Generate questions from the available specific content
        for i in range(min(num_questions, len(question_types))):
            question_type = question_types[i % len(question_types)]
            if question_type['items']:
                item = question_type['items'][0]  # Use the first item
                question_text = question_type['template'].format(item=item)
                
                # Generate specific answer for this question
                answer_prompt = f"""
                Answer this question based ONLY on what is written in this document: {question_text}
                
                Document content:
                {doc_content[:6000]}
                
                Provide a specific answer using only information from this document. If the document doesn't contain enough information to answer fully, say so.
                """
                
                try:
                    answer = self.chat(answer_prompt)
                    
                    questions.append({
                        "question": question_text,
                        "answer": answer.strip() if answer else f"This document discusses {item} in the context of the subject matter.",
                        "justification": f"This question tests specific knowledge about {item} that can only be gained by reading this document.",
                        "hint": f"Look for sections that mention or discuss {item}"
                    })
                    
                    # Remove used item to avoid repetition
                    question_type['items'].pop(0)
                    
                except Exception as e:
                    print(f"‚ö†Ô∏è Error generating answer for {item}: {e}")
                    continue
        
        return questions

    def _generate_detail_questions(self, doc_content, num_needed):
        """
        Generate additional questions based on document details and structure.
        """
        print(f"üìù Generating {num_needed} additional detail-based questions...")
        
        questions = []
        
        # Approach: Ask the AI to identify the most important details that someone should know
        detail_prompt = f"""
        After reading this document, what are {num_needed + 2} specific things that someone should know or understand? 
        These should be details, facts, or insights that are unique to THIS document.
        
        Document:
        {doc_content[:8000]}
        
        Format as:
        1. [Specific detail or fact from the document]
        2. [Another specific detail or fact from the document]
        3. [Another specific detail or fact from the document]
        
        Make sure each point is something that could ONLY be learned by reading this specific document.
        """
        
        try:
            details_response = self.chat(detail_prompt)
            
            # Extract numbered details
            import re
            details = []
            lines = details_response.split('\n')
            
            for line in lines:
                match = re.match(r'\d+\.\s*(.+)', line.strip())
                if match:
                    detail = match.group(1).strip()
                    if len(detail) > 10 and len(detail) < 200:
                        details.append(detail)
            
            # Generate questions for each detail
            for i, detail in enumerate(details[:num_needed]):
                question_text = f"Based on this document, what can you tell me about {detail.lower()}?"
                
                # Simplify answer generation
                answer_prompt = f"What does this document say about: {detail}\n\nDocument: {doc_content[:4000]}\n\nAnswer:"
                
                try:
                    answer = self.chat(answer_prompt)
                    
                    questions.append({
                        "question": question_text,
                        "answer": answer.strip() if answer else f"The document provides information about {detail}.",
                        "justification": "This question tests understanding of specific content from this document.",
                        "hint": "Look for relevant sections that discuss this topic"
                    })
                except:
                    questions.append({
                        "question": question_text,
                        "answer": f"The document discusses {detail} in detail.",
                        "justification": "This question tests understanding of document content.",
                        "hint": "Search the document for information about this topic"
                    })
                    
        except Exception as e:
            print(f"‚ö†Ô∏è Error in detail questions: {e}")
        
        return questions

    def _create_minimal_fallback(self, doc_content, num_questions):
        """
        Minimal fallback for when document is too short or extraction fails.
        """
        print("üîß Using minimal fallback questions...")
        
        # Try to extract at least some content for basic questions
        basic_prompt = f"""
        This document is short. What are the {num_questions} most important things mentioned in it?
        
        Document:
        {doc_content}
        
        List the key points:
        """
        
        try:
            response = self.chat(basic_prompt)
            
            # Create simple questions based on the response
            lines = [line.strip() for line in response.split('\n') if line.strip()]
            questions = []
            
            for i, line in enumerate(lines[:num_questions]):
                if len(line) > 5:
                    questions.append({
                        "question": f"What does this document tell us about {line.lower()}?",
                        "answer": f"The document provides information about {line}.",
                        "justification": "Based on document content analysis.",
                        "hint": "Look for relevant information in the document"
                    })
            
            # Fill remaining slots if needed
            while len(questions) < num_questions:
                questions.append({
                    "question": f"What is a key point made in this document?",
                    "answer": "The document contains important information about its subject matter.",
                    "justification": "Based on available document content.",
                    "hint": "Read through the document to identify main points"
                })
            
            return questions
            
        except:
            # Ultimate fallback
            return [{
                "question": "What is the main subject or focus of this document?",
                "answer": "The document discusses its primary subject matter.",
                "justification": "Basic content analysis.",
                "hint": "Look at the overall content and structure"
            }] * num_questions
    
    def _create_smart_content_questions(self, doc_excerpt, doc_type, num_questions):
        """
        Create smart, content-specific questions based on document analysis.
        """
        print("üß† Creating smart content-based questions...")
        
        # First, analyze the document to understand its structure and content
        analysis_prompt = f"""
        Analyze this document and identify the key topics, concepts, and important information that could be used for educational questions.
        
        Document type: {doc_type}
        
        Document content:
        {doc_excerpt[:5000]}
        
        Please identify:
        1. 3-5 main topics or concepts discussed
        2. Important facts, figures, or findings
        3. Key terminology or technical terms
        4. Methods, procedures, or processes mentioned
        5. Conclusions or recommendations
        
        Format as a simple list with clear, specific items (not full sentences).
        """
        
        try:
            analysis_response = self.chat(analysis_prompt)
            print(f"üìä Document analysis: {analysis_response[:200]}...")
            
            # Extract key concepts from the analysis
            concepts = self._extract_concepts_from_analysis(analysis_response)
            print(f"üîë Extracted concepts: {concepts}")
            
            if not concepts:
                raise Exception("No concepts extracted from analysis")
            
            # Generate questions based on these concepts
            questions = []
            question_templates = [
                "What does the document explain about {}?",
                "According to the document, what are the key aspects of {}?",
                "How does the document describe or define {}?",
                "What information does the document provide regarding {}?",
                "What conclusions or findings does the document present about {}?"
            ]
            
            for i, concept in enumerate(concepts[:num_questions]):
                template = question_templates[i % len(question_templates)]
                question_text = template.format(concept)
                
                # Generate answer for this question
                answer_prompt = f"""
                Based on this document, answer: {question_text}
                
                Document: {doc_excerpt[:4000]}
                
                Provide a specific, detailed answer using only information from the document.
                """
                
                answer = self.chat(answer_prompt)
                
                questions.append({
                    "question": question_text,
                    "answer": answer.strip(),
                    "justification": f"This concept '{concept}' is discussed in the document.",
                    "hint": f"Look for sections discussing {concept.lower()}"
                })
            
            return questions
            
        except Exception as e:
            print(f"‚ùå Error in smart content questions: {e}")
            raise e

    def _extract_concepts_from_analysis(self, analysis_text):
        """Extract clean concepts from document analysis."""
        import re
        
        # Look for numbered lists, bullet points, or clear concepts
        lines = analysis_text.split('\n')
        concepts = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # Remove numbering and bullet points
            cleaned = re.sub(r'^[\d\.\-\*\+\s]+', '', line)
            cleaned = cleaned.strip()
            
            # Skip very short or very long items
            if 5 <= len(cleaned) <= 80:
                # Clean up the concept
                cleaned = re.sub(r'[^\w\s\-]', '', cleaned)
                if cleaned and cleaned not in concepts:
                    concepts.append(cleaned)
        
        # If no good concepts found, try a different approach
        if not concepts:
            # Look for important terms in the analysis
            important_terms = re.findall(r'\b[A-Z][a-z]{3,15}\b', analysis_text)
            concepts = list(set(important_terms))[:5]
        
        return concepts[:5]

    def _create_improved_content_questions(self, doc_excerpt, num_questions):
        """
        Create questions using improved content analysis and keyword extraction.
        """
        print("üìù Creating improved content-based questions...")
        
        # Use a more focused approach to extract key topics
        topic_prompt = f"""
        From this document, extract {num_questions} specific topics, concepts, or subjects that are important and could be used for quiz questions.
        
        Document: {doc_excerpt[:4000]}
        
        Return only the topics, one per line, without explanations or numbering.
        Each topic should be 2-8 words maximum.
        """
        
        try:
            topics_response = self.chat(topic_prompt)
            topics = [line.strip() for line in topics_response.split('\n') 
                    if line.strip() and 5 <= len(line.strip()) <= 60]
            
            if not topics:
                raise Exception("No topics extracted")
            
            questions = []
            for i, topic in enumerate(topics[:num_questions]):
                # Create a specific question about this topic
                question_text = f"What does the document say about {topic}?"
                
                # Generate answer
                answer_prompt = f"""
                Answer this question using the document: {question_text}
                
                Document: {doc_excerpt[:4000]}
                
                Provide specific information from the document.
                """
                
                answer = self.chat(answer_prompt)
                
                questions.append({
                    "question": question_text,
                    "answer": answer.strip(),
                    "justification": f"The topic '{topic}' is mentioned in the document.",
                    "hint": f"Search for information about {topic.lower()}"
                })
            
            return questions
            
        except Exception as e:
            print(f"‚ùå Error in improved content questions: {e}")
            raise e

    def _extract_top_keywords(self, text, top_n=10):
        from collections import Counter
        words = re.findall(r'\b[a-z]{5,}\b', text.lower())
        stopwords = set([
            'which', 'their', 'about', 'would', 'there', 'these', 'those', 'using',
            'based', 'study', 'document', 'provide', 'provides', 'information'
        ])
        keywords = [w for w in words if w not in stopwords]
        most_common = [w for w, _ in Counter(keywords).most_common(top_n)]
        print(f"üß† Top keywords from document: {most_common}")
        return most_common


    def generate_questions(self, num_questions=3):
        """DEBUG VERSION: Generate questions with extensive logging"""
        
        print("=" * 50)
        print("üîç DEBUG: generate_questions() called")
        print(f"üìÑ Current filename: {getattr(self, 'current_filename', 'NOT SET')}")
        print(f"üìù Document loaded: {bool(getattr(self, 'current_document', None))}")
        print(f"üìä Current questions count: {len(getattr(self, 'questions', []))}")
        print("=" * 50)
        
        # FORCE clear everything
        self.questions = []
        self.current_question_index = 0
        
        print("üßπ CLEARED: All previous questions and index reset")
        
        if not hasattr(self, 'current_document') or not self.current_document:
            print("‚ùå ERROR: No document loaded!")
            return []
        
        doc_excerpt = self.current_document[:5000]
        print(f"üìñ Document excerpt length: {len(doc_excerpt)}")
        print(f"üìñ Document start: {doc_excerpt[:150]}...")
        
        # STEP 1: Test if the chat function works
        test_prompt = "What is 2+2? Just answer with a number."
        try:
            test_response = self.chat(test_prompt)
            print(f"üß™ TEST: Chat function works: {test_response}")
        except Exception as e:
            print(f"‚ùå ERROR: Chat function failed: {e}")
            return []
        
        # STEP 2: Force specific content analysis
        print("\nüîç ANALYZING DOCUMENT CONTENT...")
        
        content_prompt = f"""
        Look at this document and tell me EXACTLY what you see:
        
        FILENAME: {self.current_filename}
        
        FIRST 2000 CHARACTERS:
        {doc_excerpt[:2000]}
        
        What are 3 specific things mentioned in this text? Be very specific about what you actually see written.
        """
        
        try:
            content_analysis = self.chat(content_prompt)
            print(f"üìä CONTENT ANALYSIS RESULT:")
            print(content_analysis)
            print("=" * 30)
            
        except Exception as e:
            print(f"‚ùå ERROR in content analysis: {e}")
            content_analysis = "Failed to analyze"
        
        # STEP 3: Create questions directly from content
        print("\nüìù CREATING SPECIFIC QUESTIONS...")
        
        questions = []
        
        # Question 1: Based on filename
        if "derm" in self.current_filename.lower():
            q1 = "What dermatological conditions or treatments are discussed in this handbook?"
        elif "gender" in self.current_filename.lower():
            q1 = "What gender-related topics or issues are analyzed in this research?"
        elif "embedding" in self.current_filename.lower():
            q1 = "What word embedding techniques or bias issues are examined?"
        else:
            q1 = f"What main topics are covered in {self.current_filename}?"
        
        print(f"üéØ Q1 CREATED: {q1}")
        
        # Get answer for Q1
        answer_prompt_1 = f"""
        Answer this specific question using the document content:
        
        QUESTION: {q1}
        
        DOCUMENT: {doc_excerpt[:3000]}
        
        Give a specific answer with actual details from the document:
        """
        
        try:
            answer_1 = self.chat(answer_prompt_1)
            print(f"‚úÖ A1 GENERATED: {answer_1[:100]}...")
        except Exception as e:
            print(f"‚ùå ERROR generating A1: {e}")
            answer_1 = "Unable to generate answer due to error."
        
        questions.append({
            "question": q1,
            "answer": answer_1,
            "justification": "Based on document filename and content",
            "hint": "Look for main topics in the document"
        })
        
        # Question 2: Based on content analysis
        if "treatment" in content_analysis.lower() or "therapy" in content_analysis.lower():
            q2 = "What treatment methods or therapeutic approaches are described?"
        elif "method" in content_analysis.lower() or "analysis" in content_analysis.lower():
            q2 = "What research methods or analytical approaches are used?"
        elif "bias" in content_analysis.lower() or "gender" in content_analysis.lower():
            q2 = "What bias or gender-related findings are presented?"
        else:
            q2 = "What specific findings or results are reported in this document?"
        
        print(f"üéØ Q2 CREATED: {q2}")
        
        # Get answer for Q2
        answer_prompt_2 = f"""
        Answer: {q2}
        
        Using this document: {doc_excerpt[:3000]}
        
        Provide specific details from the text:
        """
        
        try:
            answer_2 = self.chat(answer_prompt_2)
            print(f"‚úÖ A2 GENERATED: {answer_2[:100]}...")
        except Exception as e:
            print(f"‚ùå ERROR generating A2: {e}")
            answer_2 = "Unable to generate answer due to error."
        
        questions.append({
            "question": q2,
            "answer": answer_2,
            "justification": "Based on content analysis",
            "hint": "Look for specific details in the document"
        })
        
        # Question 3: Document-specific
        if "handbook" in self.current_filename.lower():
            q3 = "What procedures, guidelines, or protocols are outlined in this handbook?"
        elif "analysis" in self.current_filename.lower():
            q3 = "What conclusions or insights does this analysis provide?"
        else:
            q3 = "What practical applications or implications are discussed?"
        
        print(f"üéØ Q3 CREATED: {q3}")
        
        # Get answer for Q3
        try:
            answer_3 = self.chat(f"Answer: {q3}\n\nDocument: {doc_excerpt[:3000]}")
            print(f"‚úÖ A3 GENERATED: {answer_3[:100]}...")
        except Exception as e:
            print(f"‚ùå ERROR generating A3: {e}")
            answer_3 = "Unable to generate answer due to error."
        
        questions.append({
            "question": q3,
            "answer": answer_3,
            "justification": "Document-specific analysis",
            "hint": "Look for practical information"
        })
        
        # FINAL STEP: Save and return
        self.questions = questions
        self.current_question_index = 0
        
        print("\n" + "=" * 50)
        print("‚úÖ FINAL QUESTIONS GENERATED:")
        for i, q in enumerate(questions):
            print(f"   Q{i+1}: {q['question']}")
        print("=" * 50)
        
        return questions

    # ALSO ADD: Function to check if questions are being called
    def debug_check_questions(self):
        """Debug function to check current state"""
        print("üîç DEBUG CHECK:")
        print(f"   Questions count: {len(getattr(self, 'questions', []))}")
        print(f"   Current index: {getattr(self, 'current_question_index', 'NOT SET')}")
        print(f"   Filename: {getattr(self, 'current_filename', 'NOT SET')}")
        
        if hasattr(self, 'questions') and self.questions:
            print("   Current questions:")
            for i, q in enumerate(self.questions):
                print(f"     Q{i+1}: {q['question'][:50]}...")
        else:
            print("   No questions found!")

    # ADD: Clear function to force reset
    def force_clear_all_state(self):
        """Force clear everything"""
        print("üßπ FORCE CLEARING ALL STATE...")
        self.questions = []
        self.current_question_index = 0
        if hasattr(self, 'current_document'):
            print(f"   Document: {len(self.current_document)} chars")
        if hasattr(self, 'current_filename'):
            print(f"   Filename: {self.current_filename}")
        print("‚úÖ State cleared!")
    

    # ALSO ADD THIS METHOD TO CLEAR STATE WHEN NEW DOCUMENT IS LOADED:
    def load_new_document(self, file_content, filename):
        """Load a new document and clear all previous state"""
        print(f"üÜï Loading NEW document: {filename}")
        
        # CLEAR ALL PREVIOUS STATE
        self.current_document = file_content
        self.current_filename = filename
        self.questions = []  # Clear old questions
        self.current_question_index = 0
        
        print("üßπ Cleared all previous questions and state")
        print("üîÑ Ready for fresh question generation")
        
        return True

    # Alternative simpler approach - you can use this instead if the above is still having issues
    def _generate_simple_content_questions(self, doc_excerpt, doc_type, num_questions):
        """Simpler, more reliable approach to question generation"""
        print("üîç Using simple content analysis for questions...")
        
        questions = []
        
        # Predefined good question patterns that work with any document
        question_patterns = [
            ("What are the main findings or conclusions presented in this document?", 
            "Look for summary statements, conclusions, or key results"),
            ("What specific topics or subjects does this document analyze in detail?", 
            "Focus on the primary themes and subjects discussed"),
            ("What methods, approaches, or perspectives does this document use?", 
            "Look for methodological approaches or analytical frameworks"),
            ("What evidence or examples does this document provide to support its points?", 
            "Focus on specific evidence, data, or case studies mentioned"),
            ("What recommendations or implications does this document suggest?", 
            "Look for suggested actions, implications, or future directions")
        ]
        
        for i in range(min(num_questions, len(question_patterns))):
            question_text, hint = question_patterns[i]
            
            try:
                # Get answer for this general question
                answer_prompt = f"""
                Based on this document, answer: {question_text}
                
                Provide specific information from the document. If the document doesn't address this aspect, 
                say so clearly.
                
                Document:
                {doc_excerpt[:4000]}
                
                Answer:"""
                
                answer = self.chat(answer_prompt)
                
                if answer:
                    clean_answer = answer.strip()
                    # Remove the question if it appears in the answer
                    if question_text in clean_answer:
                        clean_answer = clean_answer.replace(question_text, "").strip()
                    
                    questions.append({
                        "question": question_text,
                        "answer": clean_answer,
                        "justification": "This information is found in the document content",
                        "hint": hint
                    })
                
            except Exception as e:
                print(f"‚ö†Ô∏è Error with question {i+1}: {str(e)}")
                questions.append({
                    "question": question_text,
                    "answer": "This document contains relevant information that requires careful analysis.",
                    "justification": "Based on document analysis",
                    "hint": hint
                })
        
        return questions
    
    def _create_super_fast_questions(self, doc_excerpt, doc_type, num_questions):
        """
        Fast, universal fallback question generator based on top content terms.
        Fixes bug where full paragraph is misparsed as a single topic.
        """
        print("‚ö° Creating instant keyword-based questions...")

        # Prompt to extract only clean, numbered keywords
        keyword_prompt = f"""
        Extract the top {num_questions + 3} most important terms, concepts, or named entities 
        from the following document excerpt. These should be things a person could be quizzed on.

        ‚ö†Ô∏è FORMAT STRICTLY:
        Return a clean, numbered list ‚Äî no explanations, no prefix lines, no sentences.

        Example output:
        1. Debiasing
        2. Word embeddings
        3. Gender bias

        TEXT:
        {doc_excerpt[:3500]}
        """

        try:
            keyword_response = self.chat(keyword_prompt)
            lines = re.findall(r"\d+\.\s*(.+)", keyword_response.strip())
            keywords = [line.strip() for line in lines if len(line.strip()) >= 3]
            keywords = list(dict.fromkeys(keywords))[:num_questions]

        except Exception as e:
            print(f"‚ùå Keyword extraction failed: {e}")
            keywords = []

        # Generate question entries
        questions = []
        for kw in keywords:
            clean_kw = re.sub(r"[^a-zA-Z0-9\s\-]", "", kw).strip()
            if not clean_kw:
                continue

            question_text = f"What does the document say about **{clean_kw}**?"
            questions.append({
                "question": question_text,
                "answer": "Please refer to the section of the document discussing this concept.",
                "justification": f"The term '{clean_kw}' appears in the document.",
                "hint": f"Search the document for '{clean_kw}' to locate its mention."
            })

        print(f"‚úÖ Generated {len(questions)} keyword-based questions.")
        return questions





    def _quick_detect_document_type(self, content):
        """Super fast document type detection using keywords"""
        content_lower = content.lower()
        
        # Medical keywords
        medical_terms = ['patient', 'treatment', 'diagnosis', 'symptom', 'medication', 'clinical', 'therapy', 'disease', 'condition', 'medical', 'dermatology', 'skin', 'rash', 'lesion']
        medical_score = sum(1 for term in medical_terms if term in content_lower)
        
        # Legal keywords  
        legal_terms = ['law', 'legal', 'court', 'statute', 'regulation', 'contract', 'liability', 'plaintiff', 'defendant', 'jurisdiction']
        legal_score = sum(1 for term in legal_terms if term in content_lower)
        
        # Technical keywords
        tech_terms = ['procedure', 'step', 'instructions', 'manual', 'system', 'software', 'configuration', 'setup', 'installation']
        tech_score = sum(1 for term in tech_terms if term in content_lower)
        
        # Research keywords
        research_terms = ['research', 'study', 'methodology', 'analysis', 'hypothesis', 'findings', 'results', 'conclusion', 'abstract']
        research_score = sum(1 for term in research_terms if term in content_lower)
        
        # Determine type based on highest score
        scores = {
            'medical': medical_score,
            'legal': legal_score, 
            'technical': tech_score,
            'research': research_score
        }
        
        max_type = max(scores, key=scores.get)
        return max_type if scores[max_type] > 2 else 'general'


    def _create_super_fast_questions(self, doc_excerpt, doc_type, num_questions):
        """
        FIXED: Fast, universal fallback question generator based on top content terms.
        """
        print("‚ö° Creating instant keyword-based questions...")

        # Improved keyword extraction prompt
        keyword_prompt = f"""
        Extract exactly {num_questions} important topics or concepts from this document that someone could be tested on.
        
        Document: {doc_excerpt[:3000]}
        
        Return ONLY a simple list format like this:
        Topic 1
        Topic 2  
        Topic 3
        
        Each topic should be 2-6 words. No numbering, no explanations, no extra text.
        """

        try:
            keyword_response = self.chat(keyword_prompt)
            print(f"üìù Keyword response: {keyword_response}")
            
            # Clean up the response to extract actual topics
            lines = keyword_response.strip().split('\n')
            topics = []
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                    
                # Remove any numbering or bullet points
                import re
                cleaned = re.sub(r'^[\d\.\-\*\)\(]+\s*', '', line)
                cleaned = cleaned.strip()
                
                # Skip if too short, too long, or contains unwanted phrases
                if (3 <= len(cleaned) <= 60 and 
                    not cleaned.lower().startswith(('the document', 'this document', 'here are', 'topic'))):
                    topics.append(cleaned)
            
            print(f"üîë Extracted topics: {topics}")
            
            # If no good topics extracted, use document type-based fallback
            if not topics:
                topics = self._get_fallback_topics(doc_type, num_questions)
                print(f"üìã Using fallback topics: {topics}")

        except Exception as e:
            print(f"‚ùå Keyword extraction failed: {e}")
            topics = self._get_fallback_topics(doc_type, num_questions)

        # Generate questions from topics
        questions = []
        for topic in topics[:num_questions]:
            question_text = f"What information does the document provide about {topic}?"
            
            # Try to get an answer from the document
            try:
                answer_prompt = f"Based on this document, what does it say about {topic}?\n\nDocument: {doc_excerpt[:3000]}"
                answer = self.chat(answer_prompt)
            except:
                answer = f"The document contains information about {topic}. Please refer to the relevant sections for details."
            
            questions.append({
                "question": question_text,
                "answer": answer.strip() if answer else f"Information about {topic} can be found in the document.",
                "justification": f"The concept '{topic}' is discussed in the document.",
                "hint": f"Look for sections mentioning {topic.lower()}"
            })

        print(f"‚úÖ Generated {len(questions)} questions from topics.")
        return questions

    def _get_fallback_topics(self, doc_type, num_questions):
        """Get fallback topics based on document type."""
        fallback_topics = {
            'medical': ['symptoms', 'treatment', 'diagnosis', 'medication', 'procedures'],
            'research': ['methodology', 'findings', 'analysis', 'conclusions', 'data'],
            'technical': ['procedures', 'systems', 'requirements', 'implementation', 'configuration'],
            'legal': ['regulations', 'requirements', 'procedures', 'compliance', 'standards'],
            'general': ['main topics', 'key concepts', 'important information', 'conclusions', 'recommendations']
        }
        
        return fallback_topics.get(doc_type, fallback_topics['general'])[:num_questions]



    def _create_emergency_questions(self, num_questions):
        """Emergency fallback questions when everything fails"""
        return [
            {
                "question": "What is the main topic or subject of this document?",
                "answer": "The document discusses its primary subject matter with relevant details and information.",
                "justification": "Based on document content analysis",
                "hint": "Look for the central theme and key concepts discussed throughout"
            },
            {
                "question": "What specific information, facts, or data does this document provide?",
                "answer": "The document provides detailed information, facts, and data about its subject area.",
                "justification": "Based on content structure and information",
                "hint": "Focus on factual details, statistics, and specific explanations"
            },
            {
                "question": "What conclusions, recommendations, or key points does the document make?",
                "answer": "The document presents important conclusions and key insights about its topic.",
                "justification": "Based on document analysis",
                "hint": "Look for summary statements, conclusions, and main takeaway points"
            }
        ][:num_questions]

    def evaluate_challenge_answer(self, question, user_answer):
        """Evaluate a user's answer to a challenge question - FIXED VERSION"""
        try:
            import re
            import json
            
            # Ensure question is a dictionary and has required keys
            if not isinstance(question, dict):
                return {
                    "evaluation": "Error",
                    "explanation": "Invalid question format.",
                    "reference": "Not available",
                    "suggestion": "Please regenerate questions."
                }
            
            # Get question text and answer safely
            question_text = question.get('question', 'Question not available')
            correct_answer = question.get('answer', 'Answer not available')
            
            # Clean and normalize user answer
            user_answer_clean = user_answer.strip().lower()
            
            # Handle special cases first
            if not user_answer_clean or user_answer_clean in ['', 'no answer', 'skip']:
                return {
                    "evaluation": "No Answer Provided",
                    "explanation": "You didn't provide an answer to this question.",
                    "reference": question.get("justification", "Based on document content"),
                    "suggestion": "Try reading the relevant sections and attempt an answer.",
                    "correct_answer": correct_answer
                }
            
            # Handle "I don't know" responses
            if any(phrase in user_answer_clean for phrase in [
                "i don't know", "don't know", "i do not know", "do not know", 
                "not sure", "no idea", "i'm not sure", "im not sure", "unsure", "idk"
            ]):
                return {
                    "evaluation": "No Knowledge - Study Needed",
                    "explanation": "You indicated that you don't know the answer. This is honest but shows a knowledge gap that needs attention.",
                    "reference": question.get("justification", "Based on document content"),
                    "suggestion": "Review the relevant sections of the document to learn about this topic, then try again.",
                    "correct_answer": correct_answer
                }
            
            # Format the prompt for evaluation
            prompt = f"""
            You are evaluating a user's answer to a question about a document.
            
            QUESTION: {question_text}
            CORRECT ANSWER: {correct_answer}
            USER'S ANSWER: {user_answer}
            
            Evaluate the user's answer and determine if it is:
            - "Correct": The answer is accurate and demonstrates good understanding
            - "Partially Correct": The answer has some correct elements but is incomplete or has minor errors
            - "Incorrect": The answer is wrong or demonstrates misunderstanding
            
            Return your evaluation in JSON format:
            {{
                "evaluation": "Correct" or "Partially Correct" or "Incorrect",
                "explanation": "Brief explanation of why this evaluation was given",
                "reference": "Relevant reference from the document",
                "suggestion": "Specific suggestion for improvement if needed"
            }}
            """
            
            # Get response from Ollama
            response = self.chat(prompt)
            
            # Try to parse the JSON response
            try:
                # Look for JSON in the response
                json_match = re.search(r'({.*})', response.replace('\n', ' '), re.DOTALL)
                if json_match:
                    try:
                        evaluation = json.loads(json_match.group(1))
                        
                        # Add the correct answer to the response
                        evaluation["correct_answer"] = correct_answer
                        
                        return evaluation
                    except json.JSONDecodeError:
                        # If JSON parsing fails, try to extract with regex
                        evaluation_pattern = r'"evaluation":\s*"([^"]+)"'
                        explanation_pattern = r'"explanation":\s*"([^"]+)"'
                        reference_pattern = r'"reference":\s*"([^"]+)"'
                        suggestion_pattern = r'"suggestion":\s*"([^"]+)"'
                        
                        evaluation_match = re.search(evaluation_pattern, response)
                        explanation_match = re.search(explanation_pattern, response)
                        reference_match = re.search(reference_pattern, response)
                        suggestion_match = re.search(suggestion_pattern, response)
                        
                        return {
                            "evaluation": evaluation_match.group(1) if evaluation_match else "Evaluation unavailable",
                            "explanation": explanation_match.group(1) if explanation_match else "No explanation provided",
                            "reference": reference_match.group(1) if reference_match else question.get("justification", "Not available"),
                            "suggestion": suggestion_match.group(1) if suggestion_match else "No suggestions provided",
                            "correct_answer": correct_answer
                        }
                else:
                    # Fallback if JSON parsing fails completely
                    return {
                        "evaluation": "Error in evaluation",
                        "explanation": "The answer evaluation system encountered an error.",
                        "reference": question.get("justification", "Not available"),
                        "suggestion": "Please try again or contact support.",
                        "correct_answer": correct_answer
                    }
            except Exception as json_error:
                return {
                    "evaluation": "Error in evaluation",
                    "explanation": f"Could not parse evaluation result: {str(json_error)}",
                    "reference": question.get("justification", "Not available"),
                    "suggestion": "Please try again with a clearer answer.",
                    "correct_answer": correct_answer
                }
                    
        except Exception as e:
            return {
                "evaluation": "Error",
                "explanation": f"Error evaluating answer: {str(e)}",
                "reference": "Not available",
                "suggestion": "Please try again or contact support.",
                "correct_answer": question.get("answer", "Not available") if isinstance(question, dict) else "Not available"
            }